apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-30801
  labels:
    app: vllm-30801
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm-30801
  template:
    metadata:
      labels:
        app: vllm-30801
        ai-aware-router-pod: "true"
      annotations:
        ai-aware-router-address: 127.0.0.1:30801
    spec:
      containers:
      - name: vllm
        image: llm-d-inference-sim/llm-d-inference-sim:0.0.2
        args:
        - "--port=30801"
        - "--model=model1"
        - "--lora=lora1,lora2"
#        - "--time-to-first-token=500"
#        - "--inter-token-latency=100"
        ports:
          - containerPort: 30801
---
kind: Service
apiVersion: v1
metadata:
  name: vllm-30801
spec:
  type: NodePort
  selector:
    app: vllm-30801
  ports:
  - protocol: TCP
    port: 30801
    targetPort: 30801
    nodePort: 30801
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-30802
  labels:
    app: vllm-30802
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm-30802
  template:
    metadata:
      labels:
        app: vllm-30802
        ai-aware-router-pod: "true"
      annotations:
        ai-aware-router-address: 127.0.0.1:30802
    spec:
      containers:
      - name: vllm
        image: llm-d-inference-sim/llm-d-inference-sim:0.0.2
        args:
        - "--port=30802"
        - "--model=model1"
        - "--lora=lora1,lora2"
#        - "--time-to-first-token=500"
#        - "--inter-token-latency=100"
        ports:
          - containerPort: 30802
---
kind: Service
apiVersion: v1
metadata:
  name: vllm-30802
spec:
  type: NodePort
  selector:
    app: vllm-30802
  ports:
  - protocol: TCP
    port: 30802
    targetPort: 30802
    nodePort: 30802
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-30803
  labels:
    app: vllm-30803
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm-30803
  template:
    metadata:
      labels:
        app: vllm-30803
        ai-aware-router-pod: "true"
      annotations:
        ai-aware-router-address: 127.0.0.1:30803
    spec:
      containers:
      - name: vllm
        image: llm-d-inference-sim/llm-d-inference-sim:0.0.2
        args:
        - "--port=30803"
        - "--model=model2"
        - "--lora=lora3"
#        - "--time-to-first-token=500"
#        - "--inter-token-latency=100"
        ports:
          - containerPort: 30803
---
kind: Service
apiVersion: v1
metadata:
  name: vllm-30803
spec:
  type: NodePort
  selector:
    app: vllm-30803
  ports:
  - protocol: TCP
    port: 30803
    targetPort: 30803
    nodePort: 30803
